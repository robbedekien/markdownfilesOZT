---
title: "Oefeningen hoofdstuk 5 - Toetsingsprocedures"
author: "TijsMartens"
date: "3 april 2019"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# oefening 5.1. 

_(oefening zelf gemaakt, geen oplossing)_

## opgave

kunnen we in voorbeeld 5.1. zomaar veronderstellen dat het gemiddelde normaal verdeeld is, waarom

## oplossing

Ja, door de centrale limietstelling

# oefening 5.2.

_(oefening zelf gemaakt, geen oplossing)_

## opgave

Wat zou je in vergelijking 5.3. moeten veranderen opdate je de correctie kritieke waarde zou berekenen voor een linkszijdige toets

## oplossing

orginineel (voor rechtse toets):
$g = \mu + z * \frac{\sigma}{\sqrt n}$

oplossing voor linkse toets:
$g = \mu - z * \frac{\sigma}{\sqrt n}$



# oefening 5.3. 

_(oplossing vanuit de les)_

betrouwbaarheidsintervallen

## opgave

1. Wat is de onder- en bovengrens van een betrouwbaarheidsinterval van 99%? 
2. Een betrouwbaarheidsinterval van 99% is breder dan een van 95%. Waarom is dit zo? 
3. Hoe zou het betrouwbaarheidsinterval voor 100% er uit zien?

## oplossing

oplossing:

1. 
```{r}
ondergrens <- qnorm(0.01/2)
ondergrens

bovengrens <- -1 * ondergrens
bovengrens
```

2. 


Als het betrouwbaarheidsinterval 99% is is de kans groter dat een waarde binnen dit bereik valt dan als dit 95% is. Hoe groter of bredere een betrouwbaarheidsinterval hoe minder "streng" deze is.

3.  

Je bent dan 100% zeker dat het populatiegemiddelde binnen het betrouwbaarheidsinterval ligt, de volledige x-as is dan je bereik
]-oneindig, +oneindig[

elke waarde valt hier binnen


# oefening 5.4. 

_(oplossing vanuit de les)_

## opgave

 Er wordt gezegd dat het invoeren van een bindend studieadvies (BSA) een rendementsverhoging tot gevolg heeft in slaagkans. Voor het invoeren van het BSA was in de studentenpopulatie het gemiddelde aantal behaalde studiepunten per jaar per student gelijk aan 44 met een standaardafwijking van 6,2. Na invoering van het BSA wijst een onderzoek uit onder 72 studenten dat deze een gemiddeld aantal studiepunten haalden van 46,2.

## hypothesen

- $H_0 : \mu = 44$
- $H_1 : \mu > 44 (i.e. er is een rendementsverhogen$

## gegeven

- $\alpha = 2.5$
- $\sigma = 6.2$
- $n = 72$

## oplossing met overschreidingskans
```{r}
alpha <- 0.025
sigma <- 6.2
mean = 44
test = 46.2
n <- 72
p <- 1 - pnorm(test, mean, sd = sigma/sqrt(n))
p

if (p < alpha) {
  print("we mogen H0 verwerpen")
}else
{
  print("we hebben niet genoeg bewijs om H0 te verwerpen")
}
```

## oplossing van kritiek gebied
```{r}
g <- qnorm(1 - alpha, mean, sd = sigma/sqrt(n))
g

if (test > g) {
  print("we mogen H0 verwerpen")
}else
{
  print("we hebben niet genoeg bewijs om H0 te verwerpen")
}
```

# oefening 5.4. bis

_(oefening zelf gemaakt, geen oplossing)_

## algemene gegevens

```{r}
mu <- 44
sigma <- 6.2
z <- pnorm(46.2, mu, sigma)
alpha <- 0.025
n <- 72
test <- 46.2
```

## 1.

```{r}
overschreidingswaardeG <-  qnorm(1-alpha, mean, sd = sigma/sqrt(n))

overschreidingswaardeG
test
```

de te testen waarde is groter dan de kritieke grenswaarde. Het gemiddelde is dus gestegen

## 2. 

```{r}
p <- 1 -  pnorm(test, mean, sd = sigma/sqrt(n))
p
alpha
```

de overshchreingskans p (0.0013) is kleiner da alpha, we mogen $H_0$ dus verwerpen

## 3. 

als alpha 2.5% of 0.025is kunnen we veronderstellen dat 97.5% van de steekproeven bij een normaal verdeelde dataset binnen het betrouwbaarheidsinterval liggen

Als een waarde buiten de kritieke grenswaarde valt, is er slechts 2.5% kans dat hij uit de populatie getrokken is. Deze kans is dus heel klein. In dit geval met de nulhypothese verworpen worden

# oefening 5.5.

_(oefening zelf gemaakt, geen oplossing)_

## opgave

Eénvandemotievenvoorhetkiezenvaneengarageisdeinruilprijsvoordeoude auto. DeimporteurvanFordwilgraagdatdeverschillendedealerseengelijkprijsbeleidvoeren. De importeur vindt dat het gemiddelde prijsverschil tussen de dichtstbijzijnde Ford-dealer en de dealer waar men de auto gekocht heeft hoogstens e300 mag bedragen. De veronderstelling is dat als het verschil groter is, potentiële klanten eerder geneigd zullen zijn om bij hun vorige dealer te blijven.
In een steekproef worden volgende verschillen genoteerd:

400 350 400 500 300 350 200 500 200 250 250 500 350 100

Toetsoferredenisomaantenemendathetgemiddeldeprijsverschilinwerkelijkheidsigni???cant groter is dan e300. Gebruik een signi???cantieniveau van 5%.

## oplossing

```{r}
data <- c(400,350,400,500,300,350,200,500,200,250,250,500,350,100)
mean <- mean(data)
sigma <- sd(data)
alpha <- 0.05
test <- 300
n <- 14

mean
sigma

g <- qnorm(1 - alpha, mean, sd = sigma/sqrt(n))
p <- pnorm(test, mean,sd = sigma/sqrt(n))

g
## we zijn rechs aan het toetsten dus het steekproefgemiddelde ligt niet in het kritieke gebied.
##we mogen H0 niet verwerpen


p
## p is groter dan alpha, het ligt dus in het te aanvaarden gebied. we mogen de H0 niet verwerpen


```

# oefening 5.6.

## opgave

In Oefening 3.9 en volgende hebben we de resultaten van performantiemetingen voor persistentiemogelijkheden in Android geanalyseerd (Akin, 2016). Er werden experimenten uitgevoerd voor verschillende combinaties van hoeveelheid data (klein, gemiddeld, groot) en persistentietype (GreenDAO, Realm, SharedPreferences, SQLite). Voor elke hoeveelheid data hebben we kunnen bepalen welk persistentietype het beste resultaat gaf.
Nu gaan we uitzoeken of het op het eerste zicht beste persistentietype ook signi???cant beter is dan de concurrentie.
Concreet: ga aan de hand van een toets voor twee steekproeven voor elke datahoeveelheid na of het gemiddelde van het best scorende persistentietype signi???cant lager is dan het gemiddelde van (i) het tweede beste en (ii) het slechtst scorende type .
Kunnen we de conclusie aanhouden dat voor een gegeven datahoeveelheid één persistentietype het beste is, d.w.z. signi???cant beter is dan gelijk welk ander persistentietype

## oplossing

snap niet wat er gevraagd wordt


# oefening 5.7.

_(oplossing vanuit de les)_

dataset inladen:
```{r}
library(readr)

puntenlijst <- read_csv("C:/Users/tijsm/Google Drive/HoGent 2018-2019/2e semester/Onderzoekstechnieken/files/onderzoekstechnieken-cursus/oefeningen/data/hfst5_toetsing/puntenlijst.csv", col_types=cols(Groep = col_factor(levels = c("A","B","C","d","E","F","G","H"))))

puntenlijst
```

we bekijken eerst de centrummaten en spreidingsmaten voor de ganse dataset

```{r}
summarySet <- summary(puntenlijst)
summarySet
stdevSummary <- sd(puntenlijst$Score,na.rm = TRUE)
stdevSummary
```

Nu bekijken we de centrummaten en spreidingsmaten voor de verschillende klassen

```{r} 
subsetA <- puntenlijst[which(puntenlijst$Groep == "A"),]
summaryA <- summary(subsetA)
summaryA

```


```{r} 
subsetB <- puntenlijst[which(puntenlijst$Groep == "B"),]
summaryB <- summary(subsetB)
summaryB
```


```{r} 
subsetC <- puntenlijst[which(puntenlijst$Groep == "C"),]
summaryC <- summary(subsetC)
summaryC
```


```{r} 

subsetD <- puntenlijst[which(puntenlijst$Groep == "D"),]
summaryD <- summary(subsetD)
summaryD
```

```{r}  
subsetE <- puntenlijst[which(puntenlijst$Groep == "E"),]
summaryE <- summary(subsetE)
summaryE
```

```{r} 
subsetF <- puntenlijst[which(puntenlijst$Groep == "F"),]
summaryF <- summary(subsetF)
summaryF
```

```{r} 
subsetG <- puntenlijst[which(puntenlijst$Groep == "G"),]
summaryG <- summary(subsetG)
summaryG
```

```{r}
subsetH <- puntenlijst[which(puntenlijst$Groep == "H"),]
summaryH <- summary(subsetH)
summaryH
```




