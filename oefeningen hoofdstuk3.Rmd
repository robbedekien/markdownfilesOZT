---
title: "Oefeningen hoofdstuk 5 - Toetsingsprocedures"
author: "TijsMartens"
date: "3 april 2019"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# oefening 5.1. 

_(oefening zelf gemaakt, geen oplossing)_

## opgave

kunnen we in voorbeeld 5.1. zomaar veronderstellen dat het gemiddelde normaal verdeeld is, waarom

## oplossing

Ja, door de centrale limietstelling

# oefening 5.2.

_(oefening zelf gemaakt, geen oplossing)_

## opgave

Wat zou je in vergelijking 5.3. moeten veranderen opdate je de correctie kritieke waarde zou berekenen voor een linkszijdige toets

## oplossing

orginineel (voor rechtse toets):
$g = \mu + z * \frac{\sigma}{\sqrt n}$

oplossing voor linkse toets:
$g = \mu - z * \frac{\sigma}{\sqrt n}$



# oefening 5.3. 

_(oplossing vanuit de les)_

betrouwbaarheidsintervallen

## opgave

1. Wat is de onder- en bovengrens van een betrouwbaarheidsinterval van 99%? 
2. Een betrouwbaarheidsinterval van 99% is breder dan een van 95%. Waarom is dit zo? 
3. Hoe zou het betrouwbaarheidsinterval voor 100% er uit zien?

## oplossing

oplossing:

1.

betrouwbaarheisinterval = 99%
=> alpha = 1%
=> er is een tweezijdige toets, de alpha moet in de berekeningen dus gedeeld worden door 2
```{r}
ondergrens <- qnorm(0.01/2)
ondergrens


bovengrens <- -1 * ondergrens
bovengrens
```

2. 

Als een betrouwbaarheidsinterval 99% is. Dan weten weten we dat 99% procent van de populatiegemiddelden binnen het betrouwbaarheidsinterval liggen.

Bij het al dan niet verwerpen van een hypothese wordt er gekeken als de gemeten waarde binnne of buiten dit bereik valt. Als het er buiten valt, mag de hypothese verworpen worden.

Het is dus moeilijkere om een hypothese te verwerpen waarbij een betrouwbaarheidsinterval gehanteerd wordt van 99% dan bij een betrouwbaarheidsinterval van 95%

Je kan zelf bepalen hoe "streng" je je testen maakt,
* kleine alpha = breed betrouwbaarheidsinterval = moeilijk te verwerpen
* grote alpha = smaller betrouwbaarheidsinterval = makkelijker om te verwerpen


3.  

Je bent dan 100% zeker dat het populatiegemiddelde binnen het betrouwbaarheidsinterval ligt, de volledige x-as is dan je bereik
]-oneindig, +oneindig[

elke waarde valt hier binnen, dit is dus helemaal niet nuttig.


# oefening 5.4. 

_(oplossing vanuit de les)_

## opgave

 Er wordt gezegd dat het invoeren van een bindend studieadvies (BSA) een rendementsverhoging tot gevolg heeft in slaagkans. Voor het invoeren van het BSA was in de studentenpopulatie het gemiddelde aantal behaalde studiepunten per jaar per student gelijk aan 44 met een standaardafwijking van 6,2. Na invoering van het BSA wijst een onderzoek uit onder 72 studenten dat deze een gemiddeld aantal studiepunten haalden van 46,2.

## hypothesen

- $H_0 : \mu = 44$
- $H_1 : \mu > 44 (i.e. er is een rendementsverhogen$

## gegeven

- $\alpha = 2.5$
- $\sigma = 6.2$
- $n = 72$

## oplossing met overschreidingskans
```{r}
alpha <- 0.025 
sigma <- 6.2
mean = 44
test = 46.2
n <- 72
p <- 1 - pnorm(test, mean, sd = sigma/sqrt(n))
p


if (p < alpha) {
  print("we mogen H0 verwerpen")
}else
{
  print("we hebben niet genoeg bewijs om H0 te verwerpen")
}
```

de p-test levere een resultaat op van 1.3% dit is kleiner dan 2.5 procent.
het valt dus buiten het betrouwbaarheidsinterval.
Dit heeft als gevolg dat we h0 mogen verwerpen

## oplossing van kritiek gebied
formule om g te berekenen (grenswaarde)

$g = \mu + z *\frac{\sigma}{\sqrt{n}} $

```{r}
# qnorm = onder welk grens zal p% van de waarnemingen liggen

g <- qnorm(1 - alpha, mean, sd = sigma/sqrt(n))
g
test

if (test > g) {
  print("we mogen H0 verwerpen")
}else
{
  print("we hebben niet genoeg bewijs om H0 te verwerpen")
}
```


ons testgeval (waarde: 46.2) is groter dan onze grenswaarde (45.43). Omdat dit het geval is mogen we h0 verwerpen


## geef een interpretatie van wat \alpha = 2.5% betekend.

De alpha waarde bepaald hoe 'streng' we zullen testen. bij een alpha van 2.5% zullen 97.5% van de steekproefgemiddelden zicht in het aanvaardbaar gebied bevinden. 

2.5% van de waarden zullen hierbuiten vallen. Deze worden gezien als "extreem" of "significant". als het steekproefgemiddelde hiertoe behoord, kan de bijhorende nullhypothese verworpen worden.

Deze stellingen zijn enkel correct bij een normaal verdeelde set aan data

# oefening 5.4. bis

_(oefening zelf gemaakt, geen oplossing)_

## algemene gegevens

```{r}
mu <- 44
sigma <- 6.2
z <- pnorm(46.2, mu, sigma)
alpha <- 0.025
n <- 72
test <- 46.2
```

## 1.

```{r}
overschreidingswaardeG <-  qnorm(1-alpha, mean, sd = sigma/sqrt(n))

overschreidingswaardeG
test
```

de te testen waarde is groter dan de kritieke grenswaarde. Het gemiddelde is dus gestegen

## 2. 

```{r}
p <- 1 -  pnorm(test, mean, sd = sigma/sqrt(n))
p
alpha
```

de overshchreingskans p (0.0013) is kleiner da alpha, we mogen $H_0$ dus verwerpen

## 3. 

als alpha 2.5% of 0.025is kunnen we veronderstellen dat 97.5% van de steekproeven bij een normaal verdeelde dataset binnen het betrouwbaarheidsinterval liggen

Als een waarde buiten de kritieke grenswaarde valt, is er slechts 2.5% kans dat hij uit de populatie getrokken is. Deze kans is dus heel klein. In dit geval met de nulhypothese verworpen worden



# oefening 5.5.

_(oefening zelf gemaakt, geen oplossing)_

## opgave

Eén van de motieven voor het kiezen van een garage is de inruilprijs voor de oude auto. De importeur van Ford wil graag dat deverschillende dealers een gelijk prijsbeleid voeren. De importeur vindt dat het gemiddelde prijsverschil tussen de dichtstbijzijnde Ford-dealer en de dealer waar men de auto gekocht heeft hoogstens e300 mag bedragen. De veronderstelling is dat als het verschil groter is, potentiële klanten eerder geneigd zullen zijn om bij hun vorige dealer te blijven.
In een steekproef worden volgende verschillen genoteerd:

400 350 400 500 300 350 200 500 200 250 250 500 350 100

Toets of er reden is om aan te nemen dat het gemiddelde prijsverschil in werkelijkheid significant groter is dan ???300. Gebruik een significantieniveau van 5%.

## oplossing

```{r}
data <- c(400,350,400,500,300,350,200,500,200,250,250,500,350,100)
mean <- mean(data)
sigma <- sd(data)
alpha <- 0.05
test <- 300
n <- 14

mean
sigma
```

```{r}
g <- qnorm(1 - alpha, mean, sd = sigma/sqrt(n))
g
```
we zijn rechs aan het toetsten dus het steekproefgemiddelde ligt niet in het kritieke gebied.
het steekproefgemiddelde situeert zich dus wel in het aanvaardbaar gebied

we mogen H0 niet verwerpen

test = 300
grens = 386.40


```{r}
p <- pnorm(test, mean,sd = sigma/sqrt(n))
p
```
p is groter dan alpha, het ligt dus in het te aanvaarden gebied. we mogen de H0 niet verwerpen

p = 0.16
alpha = 0.05


# oefening 5.6.

## opgave

In Oefening 3.9 en volgende hebben we de resultaten van performantiemetingen voor persistentiemogelijkheden in Android geanalyseerd (Akin, 2016). Er werden experimenten uitgevoerd voor verschillende combinaties van hoeveelheid data (klein, gemiddeld, groot) en persistentietype (GreenDAO, Realm, SharedPreferences, SQLite). Voor elke hoeveelheid data hebben we kunnen bepalen welk persistentietype het beste resultaat gaf.
Nu gaan we uitzoeken of het op het eerste zicht beste persistentietype ook signi???cant beter is dan de concurrentie.
Concreet: ga aan de hand van een toets voor twee steekproeven voor elke datahoeveelheid na of het gemiddelde van het best scorende persistentietype signi???cant lager is dan het gemiddelde van (i) het tweede beste en (ii) het slechtst scorende type .
Kunnen we de conclusie aanhouden dat voor een gegeven datahoeveelheid één persistentietype het beste is, d.w.z. signi???cant beter is dan gelijk welk ander persistentietype

## oplossing
_(overgenomen van chamilo)_

inlezen data
```{r}
library(readr)

android_cpu <- read.csv("C:/Users/tijsm/Google Drive/HoGent 2018-2019/2e semester/Onderzoekstechnieken/files/onderzoekstechnieken-cursus/oefeningen/data/hfst3_1variabele/android_persistence_cpu.csv", sep=";", dec=",")
```


voorbeeld 1: medium reals & dao

1. subset nemen van alle records waarbij de datahoeveelheid medium is
```{r}
subset_medium <- subset(android_cpu, android_cpu$Datahoeveelheid=="Medium")
subset_medium
```

2. filteren van reals en dao

```{r}
times_medium_realm <- subset_medium$Tijd[which(subset_medium$PersistentieType == "Realm")]
times_medium_greendao <- subset_medium$tijd[which(subset_medium$PersistentieType == 'GreenDao')]

times_medium_realm
times_medium_realm
```

3. uitvoeren van de test

```{r}
t.test(times_medium_realm, times_medium_greendao, alternative = 'less')
```


voorbeeld 2: small voor realm & shared preferences

1. subset nemen van alle records waarbij de datahoeveelheid small is
```{r}
subset_small <- subset(android_cpu, android_cpu$Datahoeveelheid=="Weinig")
subset_small

```

2. realm en greendao filteren
```{r}
times_small_realm <- subset_small$Tijd[which(subset_medium$PersistentieType == "Realm")]
times_small_greendao <- subset_small$tijd[which(subset_medium$PersistentieType == 'GreenDao')]

times_medium_realm
times_medium_realm
```


3. uitvoeren van de t test
```{r}
t.test(times_small_realm, times_small_greendao, alternative = 'less')
```


# oefening 5.7.

_(oplossing vanuit de les)_

dataset inladen:
```{r}
library(readr)

puntenlijst <- read_csv("C:/Users/tijsm/Google Drive/HoGent 2018-2019/2e semester/Onderzoekstechnieken/files/onderzoekstechnieken-cursus/oefeningen/data/hfst5_toetsing/puntenlijst.csv", col_types=cols(Groep = col_factor(levels = c("A","B","C","d","E","F","G","H"))))

puntenlijst
```

we bekijken eerst de centrummaten en spreidingsmaten voor de ganse dataset

```{r}
summarySet <- summary(puntenlijst)
summarySet
stdevSummary <- sd(puntenlijst$Score,na.rm = TRUE)
stdevSummary
```

Nu bekijken we de centrummaten en spreidingsmaten voor de verschillende klassen

```{r} 
subsetA <- puntenlijst[which(puntenlijst$Groep == "A"),]
summaryA <- summary(subsetA)
summaryA

```


```{r} 
subsetB <- puntenlijst[which(puntenlijst$Groep == "B"),]
summaryB <- summary(subsetB)
summaryB
```


```{r} 
subsetC <- puntenlijst[which(puntenlijst$Groep == "C"),]
summaryC <- summary(subsetC)
summaryC
```


```{r} 

subsetD <- puntenlijst[which(puntenlijst$Groep == "D"),]
summaryD <- summary(subsetD)
summaryD
```

```{r}  
subsetE <- puntenlijst[which(puntenlijst$Groep == "E"),]
summaryE <- summary(subsetE)
summaryE
```

```{r} 
subsetF <- puntenlijst[which(puntenlijst$Groep == "F"),]
summaryF <- summary(subsetF)
summaryF
```

```{r} 
subsetG <- puntenlijst[which(puntenlijst$Groep == "G"),]
summaryG <- summary(subsetG)
summaryG
```

```{r}
subsetH <- puntenlijst[which(puntenlijst$Groep == "H"),]
summaryH <- summary(subsetH)
summaryH
```




